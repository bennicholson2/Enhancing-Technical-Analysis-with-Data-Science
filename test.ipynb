{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages that will be used for analysis\n",
    "import random\n",
    "\n",
    "# set the random set\n",
    "random.seed(4)\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Which Functions to be used with different demands"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "missing_data_tickers = [] # use this as a list of tickers with missing data\n",
    "\n",
    "def get_data_from_start_to_end(ticker, start_date, end_date):\n",
    "    global missing_data_tickers  # Use the global list to accumulate missing tickers\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if stock_data.empty:\n",
    "            missing_data_tickers.append(ticker)\n",
    "            raise ValueError(f\"Stock data for ticker {ticker} during the period from {start_date} to {end_date} was not found.\")\n",
    "        return stock_data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for ticker {ticker}: {e}\")\n",
    "        missing_data_tickers.append(ticker)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a variety of periods load in different list of tickers\n",
    "def download_stock_data_for_periods(tickers, periods):\n",
    "    all_data = {}\n",
    "    \n",
    "    for period, (start_date, end_date) in periods.items():\n",
    "        period_data = {}\n",
    "        for ticker in tickers:\n",
    "            data = get_data_from_start_to_end(ticker, start_date, end_date)\n",
    "            if data is not None:\n",
    "                period_data[ticker] = data\n",
    "        all_data[period] = period_data\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the adjusted close prices\n",
    "adj_close_sector_etf = {}\n",
    "\n",
    "# Create adjusted close price only listing of sector ETFs\n",
    "def get_adjusted_closed_price(nested_dict, tickers, periods):\n",
    "    for period in periods:\n",
    "        stock_price_df = pd.DataFrame()  # Create a new DataFrame for each period\n",
    "        for ticker in tickers:\n",
    "            stock_price_df[ticker] = nested_dict[period][ticker]['Adj Close']\n",
    "        \n",
    "        adj_close_sector_etf[period] = stock_price_df  # Store the complete DataFrame for the period\n",
    "    \n",
    "    return adj_close_sector_etf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bollinger bands\n",
    "import scipy.stats as stats\n",
    "def add_bollinger_data(data,window,conf_int):\n",
    "        z_score = stats.norm.ppf(1 - (1 - conf_int) / 2) # create a zscore from the mean\n",
    "\n",
    "        data['middle_band'] = data['Adj Close'].rolling(window).mean()\n",
    "        data['upper_band'] = data['middle_band'] + z_score * data['Adj Close'].rolling(window).std()\n",
    "        data['lower_band'] = data['middle_band'] - z_score * data['Adj Close'].rolling(window).std()\n",
    "\n",
    "        data['Signal'] = 'Hold'\n",
    "\n",
    "        data['Signal'] = np.where(data['Adj Close'] < data['lower_band'], 'Buy', \n",
    "                              np.where(data['Adj Close'] > data['upper_band'], 'Sell', 'Hold'))\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bollinger data for multiple time period and multiple tickers\n",
    "def bollinger_data_multiple_periods_tickers(periods,tickers,data,window,confidence_period):\n",
    "    # for each ticker in economic time periods\n",
    "    for period in periods:\n",
    "            for ticker in tickers:\n",
    "                    try:\n",
    "                        add_bollinger_data(data[period][ticker],window,confidence_period)\n",
    "                    except KeyError:\n",
    "                        print(f'Data for {ticker} does not exist during {period}')\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_signals(stock_data_with_signals, tickers, periods):\n",
    "    # Initialize a dictionary to store Buy/Sell signals\n",
    "    signals_data = {period: {ticker: {'Buy': [], 'Sell': []} for ticker in tickers} for period in periods}\n",
    "\n",
    "    for period in periods:\n",
    "        for ticker in tickers:\n",
    "            # Loop over rows in stock data for the specific period and ticker\n",
    "            for idx, row in stock_data_with_signals[period][ticker].iterrows():\n",
    "                if row['Signal'] == 'Buy':\n",
    "                    # Append the index of the Buy signal\n",
    "                    signals_data[period][ticker]['Buy'].append(pd.to_datetime(idx))\n",
    "                elif row['Signal'] == 'Sell':\n",
    "                    # Append the index of the Sell signal\n",
    "                    signals_data[period][ticker]['Sell'].append(pd.to_datetime(idx))\n",
    "\n",
    "    return signals_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_signals(nested_dict, periods, tickers):\n",
    "    # Initialize an empty dictionary to hold DataFrames for each period\n",
    "    bb_nested_dict = {}\n",
    "\n",
    "    for period in periods:\n",
    "        # Create a DataFrame for each period with the tickers as columns\n",
    "        signals_period = pd.DataFrame(columns=tickers)\n",
    "        \n",
    "        # Loop through each ticker and extract the 'Signal'\n",
    "        for ticker in tickers:\n",
    "            signals_period[ticker] = nested_dict[period][ticker]['Signal']\n",
    "        \n",
    "        # Store the DataFrame in the dictionary using the period as the key\n",
    "        bb_nested_dict[period] = signals_period\n",
    "\n",
    "    # Return the dictionary containing DataFrames for each period\n",
    "    return bb_nested_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time periods for where this takes place\n",
    "economic_cycle_periods = {\n",
    "\n",
    "    \"trough\": (\"2008-10-01\", \"2009-06-01\"),\n",
    "    \"expansion\": (\"2012-01-01\", \"2015-01-01\"),\n",
    "    \"peak\": (\"2019-06-01\", \"2020-02-01\"),\n",
    "    \"contraction\": (\"2007-12-01\", \"2008-10-01\"),\n",
    "    'all_data': ('2005-01-01','2024-06-01')\n",
    "}\n",
    "\n",
    "economic_cycle_periods_list = ['trough','expansion','peak','contraction','all_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create etf tickers for sectors\n",
    "sector_etf_tickers = [\n",
    "    'XLB', # materials sector\n",
    "    'XLI', # industrials sector\n",
    "    'XLF', # financials\n",
    "    'XLK', # information technology\n",
    "    'XLY', # consumer discretionary\n",
    "    'XLP', # consumer staples\n",
    "    'XLE', # energy\n",
    "    'XLV', # healthcare\n",
    "    'VOX', # communication services\n",
    "    'XLU', # utilities\n",
    "    'IYR' # real estate\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# save nested dictionary data as a variable to be accessed.\n",
    "sector_etf_data = download_stock_data_for_periods(sector_etf_tickers,economic_cycle_periods)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Bollinger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 20 day moving average\n",
    "# use a 95% confidence interval (2 standard deviations)\n",
    "sector_etf_data = bollinger_data_multiple_periods_tickers(economic_cycle_periods_list,sector_etf_tickers,sector_etf_data,20,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>middle_band</th>\n",
       "      <th>upper_band</th>\n",
       "      <th>lower_band</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-10-01</th>\n",
       "      <td>30.100000</td>\n",
       "      <td>30.480000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>22.927490</td>\n",
       "      <td>6053600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-02</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>29.930000</td>\n",
       "      <td>30.299999</td>\n",
       "      <td>22.965384</td>\n",
       "      <td>6353400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-03</th>\n",
       "      <td>30.600000</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>22.472729</td>\n",
       "      <td>6814400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-06</th>\n",
       "      <td>29.400000</td>\n",
       "      <td>29.879999</td>\n",
       "      <td>27.410000</td>\n",
       "      <td>28.540001</td>\n",
       "      <td>21.631418</td>\n",
       "      <td>8545000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-07</th>\n",
       "      <td>28.719999</td>\n",
       "      <td>28.780001</td>\n",
       "      <td>27.389999</td>\n",
       "      <td>27.850000</td>\n",
       "      <td>21.108452</td>\n",
       "      <td>5060200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-22</th>\n",
       "      <td>25.280001</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.070000</td>\n",
       "      <td>25.290001</td>\n",
       "      <td>19.404524</td>\n",
       "      <td>3655700</td>\n",
       "      <td>19.163589</td>\n",
       "      <td>20.034961</td>\n",
       "      <td>18.292217</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-26</th>\n",
       "      <td>25.190001</td>\n",
       "      <td>25.660000</td>\n",
       "      <td>24.889999</td>\n",
       "      <td>25.520000</td>\n",
       "      <td>19.580994</td>\n",
       "      <td>4412900</td>\n",
       "      <td>19.221135</td>\n",
       "      <td>20.041099</td>\n",
       "      <td>18.401171</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-27</th>\n",
       "      <td>25.549999</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>25.219999</td>\n",
       "      <td>25.260000</td>\n",
       "      <td>19.381495</td>\n",
       "      <td>4591100</td>\n",
       "      <td>19.265253</td>\n",
       "      <td>20.016435</td>\n",
       "      <td>18.514072</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-28</th>\n",
       "      <td>25.209999</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>25.389999</td>\n",
       "      <td>19.481239</td>\n",
       "      <td>5720000</td>\n",
       "      <td>19.310907</td>\n",
       "      <td>19.994306</td>\n",
       "      <td>18.627507</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-29</th>\n",
       "      <td>25.360001</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>25.290001</td>\n",
       "      <td>25.830000</td>\n",
       "      <td>19.818848</td>\n",
       "      <td>6549200</td>\n",
       "      <td>19.374207</td>\n",
       "      <td>19.996145</td>\n",
       "      <td>18.752270</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close   Volume  \\\n",
       "Date                                                                         \n",
       "2008-10-01  30.100000  30.480000  30.100000  30.250000  22.927490  6053600   \n",
       "2008-10-02  30.250000  30.590000  29.930000  30.299999  22.965384  6353400   \n",
       "2008-10-03  30.600000  30.600000  29.650000  29.650000  22.472729  6814400   \n",
       "2008-10-06  29.400000  29.879999  27.410000  28.540001  21.631418  8545000   \n",
       "2008-10-07  28.719999  28.780001  27.389999  27.850000  21.108452  5060200   \n",
       "...               ...        ...        ...        ...        ...      ...   \n",
       "2009-05-22  25.280001  25.400000  25.070000  25.290001  19.404524  3655700   \n",
       "2009-05-26  25.190001  25.660000  24.889999  25.520000  19.580994  4412900   \n",
       "2009-05-27  25.549999  25.600000  25.219999  25.260000  19.381495  4591100   \n",
       "2009-05-28  25.209999  25.590000  25.139999  25.389999  19.481239  5720000   \n",
       "2009-05-29  25.360001  25.840000  25.290001  25.830000  19.818848  6549200   \n",
       "\n",
       "            middle_band  upper_band  lower_band Signal  \n",
       "Date                                                    \n",
       "2008-10-01          NaN         NaN         NaN   Hold  \n",
       "2008-10-02          NaN         NaN         NaN   Hold  \n",
       "2008-10-03          NaN         NaN         NaN   Hold  \n",
       "2008-10-06          NaN         NaN         NaN   Hold  \n",
       "2008-10-07          NaN         NaN         NaN   Hold  \n",
       "...                 ...         ...         ...    ...  \n",
       "2009-05-22    19.163589   20.034961   18.292217   Hold  \n",
       "2009-05-26    19.221135   20.041099   18.401171   Hold  \n",
       "2009-05-27    19.265253   20.016435   18.514072   Hold  \n",
       "2009-05-28    19.310907   19.994306   18.627507   Hold  \n",
       "2009-05-29    19.374207   19.996145   18.752270   Hold  \n",
       "\n",
       "[166 rows x 10 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_etf_data['trough']['XLV']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_signals = collect_signals(sector_etf_data,economic_cycle_periods_list,sector_etf_tickers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Adjusted Close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_etf_closed_price = get_adjusted_closed_price(sector_etf_data,sector_etf_tickers,economic_cycle_periods_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XLB</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLF</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLE</th>\n",
       "      <th>XLV</th>\n",
       "      <th>VOX</th>\n",
       "      <th>XLU</th>\n",
       "      <th>IYR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-10-01</th>\n",
       "      <td>23.119263</td>\n",
       "      <td>21.858328</td>\n",
       "      <td>12.413446</td>\n",
       "      <td>15.649681</td>\n",
       "      <td>22.589594</td>\n",
       "      <td>18.009504</td>\n",
       "      <td>37.393242</td>\n",
       "      <td>22.927490</td>\n",
       "      <td>36.648029</td>\n",
       "      <td>18.666502</td>\n",
       "      <td>34.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-02</th>\n",
       "      <td>21.458336</td>\n",
       "      <td>20.549883</td>\n",
       "      <td>11.794874</td>\n",
       "      <td>15.037063</td>\n",
       "      <td>21.771839</td>\n",
       "      <td>17.782763</td>\n",
       "      <td>35.261120</td>\n",
       "      <td>22.965384</td>\n",
       "      <td>35.561867</td>\n",
       "      <td>18.395733</td>\n",
       "      <td>31.759171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-03</th>\n",
       "      <td>21.247202</td>\n",
       "      <td>20.222773</td>\n",
       "      <td>11.278403</td>\n",
       "      <td>14.822244</td>\n",
       "      <td>21.010752</td>\n",
       "      <td>17.640238</td>\n",
       "      <td>34.840694</td>\n",
       "      <td>22.472729</td>\n",
       "      <td>35.039406</td>\n",
       "      <td>18.119310</td>\n",
       "      <td>30.064144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-06</th>\n",
       "      <td>20.198565</td>\n",
       "      <td>19.692123</td>\n",
       "      <td>10.689858</td>\n",
       "      <td>14.002767</td>\n",
       "      <td>20.419695</td>\n",
       "      <td>17.128462</td>\n",
       "      <td>32.966839</td>\n",
       "      <td>21.631418</td>\n",
       "      <td>33.396393</td>\n",
       "      <td>17.233654</td>\n",
       "      <td>29.512156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-07</th>\n",
       "      <td>19.156969</td>\n",
       "      <td>19.037903</td>\n",
       "      <td>9.560817</td>\n",
       "      <td>13.286716</td>\n",
       "      <td>19.108046</td>\n",
       "      <td>16.584290</td>\n",
       "      <td>31.159023</td>\n",
       "      <td>21.108452</td>\n",
       "      <td>31.966496</td>\n",
       "      <td>16.528519</td>\n",
       "      <td>27.019815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-22</th>\n",
       "      <td>18.848709</td>\n",
       "      <td>16.073532</td>\n",
       "      <td>7.178293</td>\n",
       "      <td>13.618086</td>\n",
       "      <td>18.520390</td>\n",
       "      <td>15.070184</td>\n",
       "      <td>29.497360</td>\n",
       "      <td>19.404524</td>\n",
       "      <td>33.037399</td>\n",
       "      <td>14.918155</td>\n",
       "      <td>18.541613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-26</th>\n",
       "      <td>19.300217</td>\n",
       "      <td>16.658966</td>\n",
       "      <td>7.412233</td>\n",
       "      <td>13.971797</td>\n",
       "      <td>19.143745</td>\n",
       "      <td>15.260780</td>\n",
       "      <td>30.122379</td>\n",
       "      <td>19.580994</td>\n",
       "      <td>34.221863</td>\n",
       "      <td>15.351324</td>\n",
       "      <td>19.500565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-27</th>\n",
       "      <td>18.576372</td>\n",
       "      <td>16.117998</td>\n",
       "      <td>7.190606</td>\n",
       "      <td>13.835135</td>\n",
       "      <td>18.725433</td>\n",
       "      <td>14.873017</td>\n",
       "      <td>29.794714</td>\n",
       "      <td>19.381495</td>\n",
       "      <td>33.881416</td>\n",
       "      <td>15.039444</td>\n",
       "      <td>18.851517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-28</th>\n",
       "      <td>18.906044</td>\n",
       "      <td>16.273611</td>\n",
       "      <td>7.393763</td>\n",
       "      <td>14.036112</td>\n",
       "      <td>18.651628</td>\n",
       "      <td>15.030755</td>\n",
       "      <td>30.783823</td>\n",
       "      <td>19.481239</td>\n",
       "      <td>34.314068</td>\n",
       "      <td>15.351324</td>\n",
       "      <td>19.208202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-29</th>\n",
       "      <td>19.472227</td>\n",
       "      <td>16.666370</td>\n",
       "      <td>7.529203</td>\n",
       "      <td>14.188851</td>\n",
       "      <td>18.963299</td>\n",
       "      <td>15.195065</td>\n",
       "      <td>31.360292</td>\n",
       "      <td>19.818848</td>\n",
       "      <td>34.512661</td>\n",
       "      <td>15.461056</td>\n",
       "      <td>19.734451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  XLB        XLI        XLF        XLK        XLY        XLP  \\\n",
       "Date                                                                           \n",
       "2008-10-01  23.119263  21.858328  12.413446  15.649681  22.589594  18.009504   \n",
       "2008-10-02  21.458336  20.549883  11.794874  15.037063  21.771839  17.782763   \n",
       "2008-10-03  21.247202  20.222773  11.278403  14.822244  21.010752  17.640238   \n",
       "2008-10-06  20.198565  19.692123  10.689858  14.002767  20.419695  17.128462   \n",
       "2008-10-07  19.156969  19.037903   9.560817  13.286716  19.108046  16.584290   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2009-05-22  18.848709  16.073532   7.178293  13.618086  18.520390  15.070184   \n",
       "2009-05-26  19.300217  16.658966   7.412233  13.971797  19.143745  15.260780   \n",
       "2009-05-27  18.576372  16.117998   7.190606  13.835135  18.725433  14.873017   \n",
       "2009-05-28  18.906044  16.273611   7.393763  14.036112  18.651628  15.030755   \n",
       "2009-05-29  19.472227  16.666370   7.529203  14.188851  18.963299  15.195065   \n",
       "\n",
       "                  XLE        XLV        VOX        XLU        IYR  \n",
       "Date                                                               \n",
       "2008-10-01  37.393242  22.927490  36.648029  18.666502  34.011753  \n",
       "2008-10-02  35.261120  22.965384  35.561867  18.395733  31.759171  \n",
       "2008-10-03  34.840694  22.472729  35.039406  18.119310  30.064144  \n",
       "2008-10-06  32.966839  21.631418  33.396393  17.233654  29.512156  \n",
       "2008-10-07  31.159023  21.108452  31.966496  16.528519  27.019815  \n",
       "...               ...        ...        ...        ...        ...  \n",
       "2009-05-22  29.497360  19.404524  33.037399  14.918155  18.541613  \n",
       "2009-05-26  30.122379  19.580994  34.221863  15.351324  19.500565  \n",
       "2009-05-27  29.794714  19.381495  33.881416  15.039444  18.851517  \n",
       "2009-05-28  30.783823  19.481239  34.314068  15.351324  19.208202  \n",
       "2009-05-29  31.360292  19.818848  34.512661  15.461056  19.734451  \n",
       "\n",
       "[166 rows x 11 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_close_sector_etf['trough']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def backtesting_stochastic(signals_nd, adj_close_nd, periods, tickers, n_sample, analysis_type):\n",
    "    \"\"\"\n",
    "    The backtesting analysis function determines the effectiveness of different investment strategies.\n",
    "\n",
    "    - 'signals_nd': The buy, hold or sell signals - dataframe\n",
    "    - 'adj_close_nd': The adjusted close - dataframe\n",
    "    - 'periods': Different time periods to backtest - dictionary\n",
    "    - 'tickers': Different equitities to backtest - list\n",
    "    - 'n_sample': Number of model iterations\n",
    "    - 'analysis_type': The type of analysis to return ('Mean', 'Median', 'Std', 'Variance')\n",
    "    \"\"\"\n",
    "\n",
    "    roi_results = {period: {ticker: [] for ticker in tickers} for period in periods}\n",
    "\n",
    "    # Loop through each economic period\n",
    "    for period, (start_date, end_date) in periods.items():\n",
    "        date_range = pd.date_range(start=pd.to_datetime(start_date), end=pd.to_datetime(end_date) - timedelta(days=110))\n",
    "\n",
    "        # Get n start investment periods from the date range\n",
    "        start_dates = np.random.choice(date_range, size=n_sample, replace=True)\n",
    "\n",
    "        for start_date in start_dates:\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "\n",
    "            adj_close_period = adj_close_nd[period].loc[start_date:start_date+timedelta(days=110)]\n",
    "            signals = signals_nd[period].loc[start_date:start_date+timedelta(days=110)]\n",
    "\n",
    "            # Initialize variables for tracking profit/loss\n",
    "            buy_prices = {ticker: [] for ticker in tickers}  # List to track buy prices\n",
    "            total_profit = {ticker: 0 for ticker in tickers}  # Track total profit\n",
    "\n",
    "            # Iterate over signals and adjusted close prices\n",
    "            for row_idx, (signals_row, adj_close_row) in enumerate(zip(signals.iterrows(), adj_close_period.iterrows())):\n",
    "                signals_row = signals_row[1]  # Extract the signal row\n",
    "                adj_close_row = adj_close_row[1]  # Extract the adjusted close row\n",
    "\n",
    "                # Loop through each ticker's signal and corresponding adjusted close price\n",
    "                for ticker, (signal, adj_close_price) in zip(tickers, zip(signals_row, adj_close_row)):\n",
    "                    # Handle Buy action\n",
    "                    if signal == 'Buy':\n",
    "                        buy_prices[ticker].append(adj_close_price)\n",
    "\n",
    "                    # Handle Sell action (sell one share)\n",
    "                    elif signal == 'Sell' and len(buy_prices[ticker]) > 0:\n",
    "                        sell_price = adj_close_price\n",
    "                        # Sell one share (remove the first buy price from the list)\n",
    "                        buy_price = buy_prices[ticker].pop(0)\n",
    "                        profit_per_share = sell_price - buy_price\n",
    "                        total_profit[ticker] += profit_per_share\n",
    "\n",
    "            # After the 110-day period, store total profits for each ticker\n",
    "            for ticker in tickers:\n",
    "                roi_results[period][ticker].append(total_profit[ticker])\n",
    "\n",
    "    # Convert the results into a DataFrame\n",
    "    df = pd.DataFrame(index=tickers, columns=periods)\n",
    "    for period in periods:\n",
    "        for ticker in tickers:\n",
    "            data = pd.Series(roi_results[period][ticker])\n",
    "\n",
    "            if analysis_type == 'Mean':\n",
    "                df.at[ticker, period] = data.mean()\n",
    "            elif analysis_type == 'Median':\n",
    "                df.at[ticker, period] = data.median()\n",
    "            elif analysis_type == 'Std':\n",
    "                df.at[ticker, period] = data.std()\n",
    "            elif analysis_type == 'Variance':\n",
    "                df.at[ticker, period] = data.var()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trough</th>\n",
       "      <th>expansion</th>\n",
       "      <th>peak</th>\n",
       "      <th>contraction</th>\n",
       "      <th>all_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XLB</th>\n",
       "      <td>2.949972</td>\n",
       "      <td>1.244436</td>\n",
       "      <td>5.257737</td>\n",
       "      <td>2.056277</td>\n",
       "      <td>4.023275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLI</th>\n",
       "      <td>4.52528</td>\n",
       "      <td>1.681407</td>\n",
       "      <td>6.633517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.966904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLF</th>\n",
       "      <td>2.687358</td>\n",
       "      <td>1.342115</td>\n",
       "      <td>4.231771</td>\n",
       "      <td>0.50078</td>\n",
       "      <td>1.252708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLK</th>\n",
       "      <td>1.506128</td>\n",
       "      <td>1.625079</td>\n",
       "      <td>7.000872</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>3.59198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLY</th>\n",
       "      <td>6.646882</td>\n",
       "      <td>3.992257</td>\n",
       "      <td>6.730469</td>\n",
       "      <td>1.785828</td>\n",
       "      <td>4.670649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLP</th>\n",
       "      <td>1.172693</td>\n",
       "      <td>1.902352</td>\n",
       "      <td>0.263529</td>\n",
       "      <td>1.299937</td>\n",
       "      <td>1.910971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLE</th>\n",
       "      <td>7.960637</td>\n",
       "      <td>3.641978</td>\n",
       "      <td>6.080458</td>\n",
       "      <td>9.91269</td>\n",
       "      <td>2.906805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLV</th>\n",
       "      <td>2.72545</td>\n",
       "      <td>5.491496</td>\n",
       "      <td>5.415825</td>\n",
       "      <td>0.342312</td>\n",
       "      <td>3.286235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOX</th>\n",
       "      <td>11.632711</td>\n",
       "      <td>4.764721</td>\n",
       "      <td>5.044086</td>\n",
       "      <td>1.19472</td>\n",
       "      <td>2.502685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLU</th>\n",
       "      <td>1.016647</td>\n",
       "      <td>0.77443</td>\n",
       "      <td>2.417908</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>2.431945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IYR</th>\n",
       "      <td>1.95894</td>\n",
       "      <td>2.366231</td>\n",
       "      <td>1.292845</td>\n",
       "      <td>5.373918</td>\n",
       "      <td>3.154015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trough expansion      peak contraction  all_data\n",
       "XLB   2.949972  1.244436  5.257737    2.056277  4.023275\n",
       "XLI    4.52528  1.681407  6.633517         0.0  2.966904\n",
       "XLF   2.687358  1.342115  4.231771     0.50078  1.252708\n",
       "XLK   1.506128  1.625079  7.000872    0.002344   3.59198\n",
       "XLY   6.646882  3.992257  6.730469    1.785828  4.670649\n",
       "XLP   1.172693  1.902352  0.263529    1.299937  1.910971\n",
       "XLE   7.960637  3.641978  6.080458     9.91269  2.906805\n",
       "XLV    2.72545  5.491496  5.415825    0.342312  3.286235\n",
       "VOX  11.632711  4.764721  5.044086     1.19472  2.502685\n",
       "XLU   1.016647   0.77443  2.417908    0.005936  2.431945\n",
       "IYR    1.95894  2.366231  1.292845    5.373918  3.154015"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest = backtesting_stochastic(bb_signals,adj_close_sector_etf,economic_cycle_periods,sector_etf_tickers,100,'Mean')\n",
    "backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_stock_roi(bb_signals_nd, adj_close_nd, periods_date, periods_list, tickers, n_sample, initial_investment, future_investments, percent_to_buy, percent_to_sell):\n",
    "    # Initialize a nested dictionary to store ROI percentages for each period and ticker\n",
    "    roi_results = {period: {ticker: [] for ticker in tickers} for period in periods_list}\n",
    "\n",
    "    # Loop through each economic period\n",
    "    for period in periods_list:\n",
    "        # Create the date range for the current period\n",
    "        date_range = pd.date_range(start=pd.to_datetime(periods_date[period][0]), end=pd.to_datetime(periods_date[period][1]) - timedelta(days=90))\n",
    "        \n",
    "        # Get random dates for stochastic modeling\n",
    "        start_dates = np.random.choice(date_range, size=n_sample, replace=True)\n",
    "\n",
    "        # Loop through sampled start dates\n",
    "        for start_date in start_dates:\n",
    "            time_stamp = pd.to_datetime(start_date)\n",
    "\n",
    "            # Extract the adjusted close and signal data for time period\n",
    "            adj_close_period = adj_close_nd[period].loc[time_stamp:time_stamp + timedelta(days=90)]\n",
    "            bb_signals_period = bb_signals_nd[period].loc[time_stamp:time_stamp + timedelta(days=90)]\n",
    "\n",
    "            # Initialize variables for each ticker\n",
    "            account_balance = {ticker: future_investments for ticker in tickers}  # Separate account balance for each stock\n",
    "            shares_number = {ticker: initial_investment/adj_close_period[ticker].iloc[0] for ticker in tickers}  # Initialize share count for each ticker\n",
    "            shares_value = {ticker: initial_investment for ticker in tickers}   # Initialize share value for each ticker\n",
    "\n",
    "            # Iterate over each day in the Bollinger Band signals and adjusted close prices\n",
    "            for row_idx, (signals_row, adj_close_row) in enumerate(zip(bb_signals_period.iterrows(), adj_close_period.iterrows())):\n",
    "                signals_row = signals_row[1]  # Extract the actual row (signals) - don't need the index\n",
    "                adj_close_row = adj_close_row[1]  # Extract the actual row (adjusted close prices)\n",
    "\n",
    "                # Now zip over the signal row and the corresponding adjusted close price for each ticker\n",
    "                for ticker, (signal, adj_close_price) in zip(tickers, zip(signals_row, adj_close_row)):\n",
    "                    \n",
    "                    # Handle Buy action\n",
    "                    if signal == 'Buy':\n",
    "                        amount_to_buy = percent_to_buy * account_balance[ticker]\n",
    "                        if account_balance[ticker] >= amount_to_buy:\n",
    "                            shares_to_buy = amount_to_buy / adj_close_price\n",
    "                            shares_number[ticker] += shares_to_buy\n",
    "                            account_balance[ticker] -= amount_to_buy\n",
    "\n",
    "                    # Handle Sell action\n",
    "                    elif signal == 'Sell':\n",
    "                        if shares_number[ticker] > 0:\n",
    "                            shares_value[ticker] = shares_number[ticker] * adj_close_price\n",
    "                            amount_to_sell = percent_to_sell * shares_value[ticker]\n",
    "                            if shares_value[ticker] >= amount_to_sell:\n",
    "                                shares_to_sell = amount_to_sell / adj_close_price\n",
    "                                shares_number[ticker] -= shares_to_sell\n",
    "                                account_balance[ticker] += amount_to_sell\n",
    "\n",
    "            # Calculate total portfolio value for each stock at the end of the period\n",
    "            for ticker in tickers:\n",
    "                if shares_number[ticker] > 0:  # Only calculate value if shares are owned\n",
    "                    portfolio_value = shares_number[ticker] * adj_close_period.iloc[-1][ticker]\n",
    "                    total_value = account_balance[ticker] + portfolio_value\n",
    "                    \n",
    "                    # Calculate profit for this stock\n",
    "                    profit = total_value - (initial_investment + future_investments)\n",
    "                    \n",
    "                    # Calculate ROI based on stock's individual account\n",
    "                    roi_dollar_value = (profit / (initial_investment + future_investments)) * 100\n",
    "                else:\n",
    "                    roi_dollar_value = 0\n",
    "\n",
    "                # Store ROI in the results dictionary\n",
    "                roi_results[period][ticker].append(roi_dollar_value)\n",
    "\n",
    "    return roi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_roi(tickers,periods,return_rates_list,analysis_type):\n",
    "    df = pd.DataFrame(index=tickers,columns=periods)\n",
    "    for period in periods:\n",
    "        for ticker in tickers:\n",
    "            data = pd.Series(return_rates_list[period][ticker])\n",
    "            if analysis_type=='Mean':\n",
    "                df.at[ticker,period] = data.mean()\n",
    "            elif analysis_type=='Median':\n",
    "                df.at[ticker,period] = data.median()\n",
    "            elif analysis_type=='Std':\n",
    "                df.at[ticker,period] = data.std()\n",
    "            elif analysis_type=='Variance':\n",
    "                df.at[ticker,period] = data.var()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trough         3.331125\n",
       "expansion      0.924380\n",
       "peak           1.122377\n",
       "contraction    0.331041\n",
       "all_data       0.827272\n",
       "dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = calculate_stock_roi(bb_signals,adj_close_sector_etf,economic_cycle_periods,economic_cycle_periods,sector_etf_tickers,10,0,100,0.,0.2)\n",
    "stochastic_roi(sector_etf_tickers,economic_cycle_periods_list,a,'Mean').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
