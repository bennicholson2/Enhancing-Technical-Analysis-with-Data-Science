{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "missing_data_tickers = [] # use this as a list of tickers with missing data\n",
    "\n",
    "def get_data_from_start_to_end(ticker, start_date, end_date):\n",
    "    global missing_data_tickers  # Use the global list to accumulate missing tickers\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if stock_data.empty:\n",
    "            missing_data_tickers.append(ticker)\n",
    "            raise ValueError(f\"Stock data for ticker {ticker} during the period from {start_date} to {end_date} was not found.\")\n",
    "        return stock_data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for ticker {ticker}: {e}\")\n",
    "        missing_data_tickers.append(ticker)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a variety of periods load in different list of tickers\n",
    "def download_stock_data_for_periods(tickers, periods):\n",
    "    all_data = {}\n",
    "    \n",
    "    for period, (start_date, end_date) in periods.items():\n",
    "        period_data = {}\n",
    "        for ticker in tickers:\n",
    "            data = get_data_from_start_to_end(ticker, start_date, end_date)\n",
    "            if data is not None:\n",
    "                period_data[ticker] = data\n",
    "        all_data[period] = period_data\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the adjusted close prices\n",
    "adj_close_sector_etf = {}\n",
    "\n",
    "# Create adjusted close price only listing of sector ETFs\n",
    "def get_adjusted_closed_price(nested_dict, tickers, periods):\n",
    "    for period in periods:\n",
    "        stock_price_df = pd.DataFrame()  # Create a new DataFrame for each period\n",
    "        for ticker in tickers:\n",
    "            stock_price_df[ticker] = nested_dict[period][ticker]['Adj Close']\n",
    "        \n",
    "        adj_close_sector_etf[period] = stock_price_df  # Store the complete DataFrame for the period\n",
    "    \n",
    "    return adj_close_sector_etf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def stochastic_modeling(nested_dict, tickers, periods,num_samples):\n",
    "    # Store the returns in a nested dictionary\n",
    "    nested_dict_returns = {period: {ticker: [] for ticker in tickers} for period in periods}\n",
    "\n",
    "    # Go through each economic time period\n",
    "    for period in periods:\n",
    "        max_index = len(nested_dict[period]) - 30  # Ensure there's enough data to calculate ROI\n",
    "\n",
    "        # Generate random samples from the valid range\n",
    "        random_dates = random.choices(range(max_index), k=num_samples)\n",
    "\n",
    "        for ticker in tickers:\n",
    "            for date_idx in random_dates:\n",
    "                start_price = nested_dict[period][ticker].iloc[date_idx]\n",
    "                end_price = nested_dict[period][ticker].iloc[date_idx + 30]\n",
    "\n",
    "                # Get the return by the Holding Period Return\n",
    "                roi = (((end_price - start_price) / start_price) * 100)\n",
    "\n",
    "                nested_dict_returns[period][ticker].append(roi)\n",
    "\n",
    "    return nested_dict_returns  # Return the nested dictionary with returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_roi(tickers,periods,return_rates_list,analysis_type):\n",
    "    df = pd.DataFrame(index=tickers,columns=periods)\n",
    "    for period in periods:\n",
    "        for ticker in tickers:\n",
    "            data = pd.Series(return_rates_list[period][ticker])\n",
    "            if analysis_type=='Mean':\n",
    "                df.at[ticker,period] = data.mean()\n",
    "            elif analysis_type=='Median':\n",
    "                df.at[ticker,period] = data.median()\n",
    "            elif analysis_type=='Std':\n",
    "                df.at[ticker,period] = data.std()\n",
    "            elif analysis_type=='Variance':\n",
    "                df.at[ticker,period] = data.var()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buy and Hold Investment Technique\n",
    "The buy and hold strategy is a passive investing strategy that will be applied to the 11 sector ETFs during different macroeconomic time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time periods for where this takes place\n",
    "economic_cycle_periods = {\n",
    "\n",
    "    \"trough\": (\"2008-10-01\", \"2009-06-01\"),\n",
    "    \"expansion\": (\"2012-01-01\", \"2015-01-01\"),\n",
    "    \"peak\": (\"2019-06-01\", \"2020-02-01\"),\n",
    "    \"contraction\": (\"2007-12-01\", \"2008-10-01\"),\n",
    "}\n",
    "\n",
    "economic_cycle_periods_list = ['trough','expansion','peak','contraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create etf tickers for sectors\n",
    "sector_etf_tickers = [\n",
    "    'XLB', # materials sector\n",
    "    'XLI', # industrials sector\n",
    "    'XLF', # financials\n",
    "    'XLK', # information technology\n",
    "    'XLY', # consumer discretionary\n",
    "    'XLP', # consumer staples\n",
    "    'XLE', # energy\n",
    "    'XLV', # healthcare\n",
    "    'VOX', # communication services\n",
    "    'XLU', # utilities\n",
    "    'IYR' # real estate\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# save nested dictionary data as a variable to be accessed.\n",
    "sector_etf_data = download_stock_data_for_periods(sector_etf_tickers,economic_cycle_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adjusted close price\n",
    "sector_etf_adjusted_close = get_adjusted_closed_price(sector_etf_data,sector_etf_tickers,economic_cycle_periods_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform stochastic modeling using buy and hold strategy\n",
    "Use a different day where the stock begins investing then hold for a month and see the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stochastic modeling on the buy and \n",
    "stochastic_buy_hold = stochastic_modeling(sector_etf_adjusted_close,sector_etf_tickers,economic_cycle_periods_list,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trough</th>\n",
       "      <th>expansion</th>\n",
       "      <th>peak</th>\n",
       "      <th>contraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XLB</th>\n",
       "      <td>1.272944</td>\n",
       "      <td>1.48503</td>\n",
       "      <td>1.198677</td>\n",
       "      <td>-1.186616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLI</th>\n",
       "      <td>-0.873409</td>\n",
       "      <td>2.164375</td>\n",
       "      <td>2.022506</td>\n",
       "      <td>-1.944523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLF</th>\n",
       "      <td>-2.204338</td>\n",
       "      <td>2.637947</td>\n",
       "      <td>2.766903</td>\n",
       "      <td>-4.647609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLK</th>\n",
       "      <td>1.529493</td>\n",
       "      <td>2.111732</td>\n",
       "      <td>4.472099</td>\n",
       "      <td>-2.649538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLY</th>\n",
       "      <td>2.231488</td>\n",
       "      <td>2.540581</td>\n",
       "      <td>1.447289</td>\n",
       "      <td>-0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLP</th>\n",
       "      <td>-1.393381</td>\n",
       "      <td>2.109823</td>\n",
       "      <td>1.949633</td>\n",
       "      <td>-0.079942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLE</th>\n",
       "      <td>0.26154</td>\n",
       "      <td>0.794221</td>\n",
       "      <td>-0.098585</td>\n",
       "      <td>-1.083695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLV</th>\n",
       "      <td>-0.969988</td>\n",
       "      <td>3.070623</td>\n",
       "      <td>2.772104</td>\n",
       "      <td>-1.649997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOX</th>\n",
       "      <td>2.578617</td>\n",
       "      <td>1.75983</td>\n",
       "      <td>2.452495</td>\n",
       "      <td>-3.364605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLU</th>\n",
       "      <td>-1.14542</td>\n",
       "      <td>1.773651</td>\n",
       "      <td>2.334167</td>\n",
       "      <td>-2.595899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IYR</th>\n",
       "      <td>-2.490634</td>\n",
       "      <td>1.624909</td>\n",
       "      <td>1.501922</td>\n",
       "      <td>0.018284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trough expansion      peak contraction\n",
       "XLB  1.272944   1.48503  1.198677   -1.186616\n",
       "XLI -0.873409  2.164375  2.022506   -1.944523\n",
       "XLF -2.204338  2.637947  2.766903   -4.647609\n",
       "XLK  1.529493  2.111732  4.472099   -2.649538\n",
       "XLY  2.231488  2.540581  1.447289   -0.954601\n",
       "XLP -1.393381  2.109823  1.949633   -0.079942\n",
       "XLE   0.26154  0.794221 -0.098585   -1.083695\n",
       "XLV -0.969988  3.070623  2.772104   -1.649997\n",
       "VOX  2.578617   1.75983  2.452495   -3.364605\n",
       "XLU  -1.14542  1.773651  2.334167   -2.595899\n",
       "IYR -2.490634  1.624909  1.501922    0.018284"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_roi(sector_etf_tickers,economic_cycle_periods_list,stochastic_buy_hold,'Mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger Bands Investment Technique\n",
    "Using John Bollinger's techniques 'Bollinger Bands' to create buy and sell signals to observe the roi for investing for a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bollinger data\n",
    "import scipy.stats as stats\n",
    "def add_bollinger_data(data,window,conf_int):\n",
    "        z_score = stats.norm.ppf(1 - (1 - conf_int) / 2) # create a zscore from the mean\n",
    "\n",
    "        data['middle_band'] = data['Adj Close'].rolling(window).mean()\n",
    "        data['upper_band'] = data['middle_band'] + z_score * data['Adj Close'].rolling(window).std()\n",
    "        data['lower_band'] = data['middle_band'] - z_score * data['Adj Close'].rolling(window).std()\n",
    "\n",
    "        data['Signal'] = None\n",
    "\n",
    "        data['Signal'] = np.where(data['Adj Close'] < data['lower_band'], 'Buy', \n",
    "                              np.where(data['Adj Close'] > data['upper_band'], 'Sell', np.nan))\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bollinger data for multiple time period and multiple tickers\n",
    "def bollinger_data_multiple_periods_tickers(periods,tickers,data,window,confidence_period):\n",
    "    # for each ticker in economic time periods\n",
    "    for period in periods:\n",
    "            for ticker in tickers:\n",
    "                    try:\n",
    "                        add_bollinger_data(data[period][ticker],window,confidence_period)\n",
    "                    except KeyError:\n",
    "                        print(f'Data for {ticker} does not exist during {period}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bollinger bands in stock data\n",
    "bollinger_data_multiple_periods_tickers(economic_cycle_periods_list,sector_etf_tickers,sector_etf_data,20,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan     670\n",
       "Buy      45\n",
       "Sell     39\n",
       "Name: Signal, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example case of bollinger bands in stock data\n",
    "sector_etf_data['expansion']['XLB']['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_signals(nested_dict, periods, tickers):\n",
    "    # Initialize an empty dictionary to hold DataFrames for each period\n",
    "    bb_nested_dict = {}\n",
    "\n",
    "    for period in periods:\n",
    "        # Create a DataFrame for each period with the tickers as columns\n",
    "        signals_period = pd.DataFrame(columns=tickers)\n",
    "        \n",
    "        # Loop through each ticker and extract the 'Signal'\n",
    "        for ticker in tickers:\n",
    "            signals_period[ticker] = nested_dict[period][ticker]['Signal']\n",
    "        \n",
    "        # Store the DataFrame in the dictionary using the period as the key\n",
    "        bb_nested_dict[period] = signals_period\n",
    "\n",
    "    # Return the dictionary containing DataFrames for each period\n",
    "    return bb_nested_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_bands_signals = collect_signals(sector_etf_data,economic_cycle_periods_list,sector_etf_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sector_etf_adjusted_close) == len(bb_bands_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for signals \n",
    "def bb_band_roi(bb_signals_nd, adj_close_nd,periods,tickers,n_sample):\n",
    "    # create a nested dictionary with technical analysis signals and adj close price as pages\n",
    "    all_data = {\n",
    "        'Adj Close': adj_close_nd,\n",
    "        'Bollinger Band': bb_signals_nd\n",
    "    }\n",
    "\n",
    "    # create start index dates\n",
    "    random_dates = random.choices(range(max_index),k=n_sample)\n",
    "\n",
    "    # go through each period\n",
    "    for period in periods:\n",
    "        # go through each day in the signals then collect the location\n",
    "        for row_idx, row in all_data['Bollinger Band'][period].iterrows():\n",
    "            for col_idx,value in enumerate(row):\n",
    "                for ticker in tickers:\n",
    "                    if row[value]=='Buy':\n",
    "                        adj_close_price = adj_close_nd.iloc[col_idx,row_idx]\n",
    "                        print(f'buy ticker {col_idx} at day {row_idx} ')\n",
    "                        print(f'at price {adj_close_price}')\n",
    "                    elif row[ticker] == 'Sell':\n",
    "                        print(f'sell ticker {col_idx} at day {row_idx}')\n",
    "                        adj_close_price = adj_close_nd.iloc[col_idx,row_idx]\n",
    "                        print(f'at price {adj_close_price}')\n",
    "                    else: continue\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # get the max index so that there is a month of investing time\n",
    "    max_index = len(adj_close_nd[period]-30)\n",
    "\n",
    "    # this is your own keep working\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bb_band_roi(bb_signals_nd, adj_close_nd, periods, tickers, n_sample):\n",
    "    # Ensure we have valid data and calculate max index\n",
    "    if adj_close_nd is None or len(adj_close_nd) < 30:\n",
    "        raise ValueError(\"Not enough data for a 30-day investment period\")\n",
    "\n",
    "    # Get the max index so that there is a month (30 days) of investing time\n",
    "    max_index = len(adj_close_nd) - 30\n",
    "\n",
    "    # Generate random start indices for sampling investment periods\n",
    "    random_dates = random.choices(range(max_index), k=n_sample)\n",
    "\n",
    "    # Create a nested dictionary with technical analysis signals and adj close price as pages\n",
    "    all_data = {\n",
    "        'Adj Close': adj_close_nd,\n",
    "        'Bollinger Band': bb_signals_nd\n",
    "    }\n",
    "\n",
    "    # Loop through each period\n",
    "    for period in periods:\n",
    "        # Loop through each sampled starting date (randomized investment windows)\n",
    "        for start_idx in random_dates:\n",
    "            end_idx = start_idx + 30  # Define the investment period to last for 30 days\n",
    "\n",
    "            # Loop through each day within this 30-day period\n",
    "            for row_idx, row in all_data['Bollinger Band'][period].iloc[start_idx:end_idx].iterrows():\n",
    "                # Loop through each ticker\n",
    "                for col_idx, ticker in enumerate(tickers):\n",
    "                    signal = row[ticker]  # Get the Buy/Sell signal for the ticker\n",
    "                    adj_close_price = all_data['Adj Close'].iloc[row_idx, col_idx]\n",
    "\n",
    "                    # Execute trade based on signal\n",
    "                    if signal == 'Buy':\n",
    "                        print(f\"Buy ticker {ticker} at day {row_idx}, price {adj_close_price}\")\n",
    "                    elif signal == 'Sell':\n",
    "                        print(f\"Sell ticker {ticker} at day {row_idx}, price {adj_close_price}\")\n",
    "\n",
    "                    # Continue to next day if no signal is generated\n",
    "                    else:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not enough data for a 30-day investment period",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6q/lw13gkln44z1r6ncfrmcbc5w0000gn/T/ipykernel_87882/1849971217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbb_band_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_bands_signals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msector_etf_adjusted_close\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meconomic_cycle_periods_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msector_etf_tickers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6q/lw13gkln44z1r6ncfrmcbc5w0000gn/T/ipykernel_87882/3028615666.py\u001b[0m in \u001b[0;36mbb_band_roi\u001b[0;34m(bb_signals_nd, adj_close_nd, periods, tickers, n_sample)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Ensure we have valid data and calculate max index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madj_close_nd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_close_nd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough data for a 30-day investment period\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Get the max index so that there is a month (30 days) of investing time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough data for a 30-day investment period"
     ]
    }
   ],
   "source": [
    "bb_band_roi(bb_bands_signals,sector_etf_adjusted_close,economic_cycle_periods_list,sector_etf_tickers,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
